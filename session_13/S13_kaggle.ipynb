{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4","include_colab_link":true},"widgets":{"application/vnd.jupyter.widget-state+json":{"b860dacd46b742a999f5fadedb6b5884":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1e2aeaa64b48448fb0c1c0879a895cc6","IPY_MODEL_2259bcf6d7db4b219baa770fea64c831","IPY_MODEL_9ac75756832f411e97447a0f99b57e65"],"layout":"IPY_MODEL_677471cd448f4eb886d9efbb73beff0b"}},"1e2aeaa64b48448fb0c1c0879a895cc6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_281339e008cf4cc8847168d8ee349539","placeholder":"​","style":"IPY_MODEL_a580d35996cd4ae0996b346ed270317f","value":" 74%"}},"2259bcf6d7db4b219baa770fea64c831":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_d94579df92c9427f8375b2f5d13673cc","max":200,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f940feab7ffe4abfbca64e58d1ba57e4","value":148}},"9ac75756832f411e97447a0f99b57e65":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_65d6c08800004855a545dac338cdc89e","placeholder":"​","style":"IPY_MODEL_52333d2b01104c418db95df1668a15fd","value":" 148/200 [03:20&lt;01:32,  1.78s/it]"}},"677471cd448f4eb886d9efbb73beff0b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"281339e008cf4cc8847168d8ee349539":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a580d35996cd4ae0996b346ed270317f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d94579df92c9427f8375b2f5d13673cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f940feab7ffe4abfbca64e58d1ba57e4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"65d6c08800004855a545dac338cdc89e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52333d2b01104c418db95df1668a15fd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/jyanivaddi/ERA_V1/blob/master/session_13/s13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github","colab_type":"text"}},{"cell_type":"markdown","source":"First Connect Google Drive","metadata":{"id":"OZ4DqRTb9Ym8"}},{"cell_type":"code","source":"#from google.colab import drive\n#drive.mount('/content/gdrive/', force_remount=True)","metadata":{"id":"TDhBByBZ8qi9","outputId":"74ecf808-1a81-4f0d-d197-3614327b21d8","colab":{"base_uri":"https://localhost:8080/"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Install packages","metadata":{"id":"cgHQxuQMAJ5o"}},{"cell_type":"code","source":"!git clone \"https://github.com/jyanivaddi/ERA_V1.git\"\n!git -C ERA_V1 pull\n#!cd ../\n!git clone \"https://github.com/jyanivaddi/dl_hub.git\"\n!git -C dl_hub pull\n!git pull\n#!cd ../\n\n!pip install --quiet \"torchinfo\" \"seaborn\" \"pytorch-lightning\" \"torchmetrics\" \"lightning-bolts\"\n!pip install --quiet \"prettytable\"\n!pip install --quiet \"torch_lr_finder\"\n!pip install --quiet \"grad-cam\"\n!pip install --quiet \"gradio\"","metadata":{"id":"VAOiUa_mAJVQ","outputId":"85e7cb94-0062-4173-f106-05d14f0d42b1","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2023-08-10T13:02:00.218123Z","iopub.execute_input":"2023-08-10T13:02:00.218542Z","iopub.status.idle":"2023-08-10T13:02:50.501848Z","shell.execute_reply.started":"2023-08-10T13:02:00.218507Z","shell.execute_reply":"2023-08-10T13:02:50.500583Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"fatal: destination path 'ERA_V1' already exists and is not an empty directory.\nAlready up to date.\nfatal: destination path 'dl_hub' already exists and is not an empty directory.\nAlready up to date.\nThere is no tracking information for the current branch.\nPlease specify which branch you want to merge with.\nSee git-pull(1) for details.\n\n    git pull <remote> <branch>\n\nIf you wish to set tracking information for this branch you can do so with:\n\n    git branch --set-upstream-to=origin/<branch> master\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import sys\nsys.path.append(\"ERA_V1/session_13\")\nsys.path.append(\"dl_hub\")","metadata":{"id":"ivBzl8YFPvJ0","execution":{"iopub.status.busy":"2023-08-10T13:07:14.913626Z","iopub.execute_input":"2023-08-10T13:07:14.915715Z","iopub.status.idle":"2023-08-10T13:07:14.921640Z","shell.execute_reply.started":"2023-08-10T13:07:14.915665Z","shell.execute_reply":"2023-08-10T13:07:14.920589Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"!git -C dl_hub pull\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n41Pe-b1J3mC","outputId":"2d7d2842-8bfc-459a-beb0-11002dcb6484","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import dl_hub.models.YOLO_V3.config as config\nimport torch\nimport torch.optim as optim\n\nfrom dl_hub.models.YOLO_V3.model import YOLOv3\nfrom tqdm import tqdm\nfrom dl_hub.models.YOLO_V3.utils import (\n    mean_average_precision,\n    cells_to_bboxes,\n    get_evaluation_bboxes,\n    save_checkpoint,\n    load_checkpoint,\n    check_class_accuracy,\n    get_loaders,\n    plot_couple_examples\n)\nfrom dl_hub.models.YOLO_V3.loss import YoloLoss\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"id":"x8WpKATx75Hu","execution":{"iopub.status.busy":"2023-08-10T13:07:18.403646Z","iopub.execute_input":"2023-08-10T13:07:18.405061Z","iopub.status.idle":"2023-08-10T13:07:22.749142Z","shell.execute_reply.started":"2023-08-10T13:07:18.405027Z","shell.execute_reply":"2023-08-10T13:07:22.747116Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"# NO NEED TO RUN THIS....FOR REFERENCE ONLY\ndef train_fn(train_loader, model, optimizer, loss_fn, scaler, scaled_anchors, scheduler):\n    loop = tqdm(train_loader, leave=True)\n    losses = []\n    for batch_idx, (x, y) in enumerate(loop):\n        x = x.to(config.DEVICE)\n        y0, y1, y2 = (\n            y[0].to(config.DEVICE),\n            y[1].to(config.DEVICE),\n            y[2].to(config.DEVICE),\n        )\n\n        with torch.cuda.amp.autocast():\n            out = model(x)\n            loss = (\n                loss_fn(out[0], y0, scaled_anchors[0])\n                + loss_fn(out[1], y1, scaled_anchors[1])\n                + loss_fn(out[2], y2, scaled_anchors[2])\n            )\n\n        losses.append(loss.item())\n        optimizer.zero_grad()\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        scheduler.step()\n\n        # update progress bar\n        mean_loss = sum(losses) / len(losses)\n        loop.set_postfix(loss=mean_loss)","metadata":{"id":"w4GDrpX975Hx","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# NO NEED TO RUN THIS....FOR REFERENCE ONLY\ntorch.cuda.empty_cache()","metadata":{"id":"TDkVV-JtKJUI","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# NO NEED TO RUN THIS....FOR REFERENCE ONLY\n\nmodel = YOLOv3(num_classes=config.NUM_CLASSES).to(config.DEVICE)\noptimizer = optim.Adam(\n    model.parameters(), lr=config.LEARNING_RATE, weight_decay=config.WEIGHT_DECAY\n)\nloss_fn = YoloLoss()\nscaler = torch.cuda.amp.GradScaler()\n\ntrain_loader, test_loader, train_eval_loader = get_loaders(\n    train_csv_path=config.DATASET + \"/100examples.csv\", test_csv_path=config.DATASET + \"/8examples.csv\"\n)\n\nif config.LOAD_MODEL:\n    load_checkpoint(\n        config.CHECKPOINT_FILE, model, optimizer, config.LEARNING_RATE\n    )\n","metadata":{"id":"3DtkSQ9b75H0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# NO NEED TO RUN THIS....FOR REFERENCE ONLY\n\nfrom torch_lr_finder import LRFinder\nuse_cuda = torch.cuda.is_available()\ndevice = torch.device(\"cuda\" if use_cuda else \"cpu\")\n\nscaled_anchors = (\n    torch.tensor(config.ANCHORS)\n    * torch.tensor(config.S).unsqueeze(1).unsqueeze(1).repeat(1, 3, 2)\n).to(config.DEVICE)\n\ndef criterion(out, y):\n    y0, y1, y2 = (\n            y[0].to(config.DEVICE),\n            y[1].to(config.DEVICE),\n            y[2].to(config.DEVICE),\n        )\n    loss = (\n                loss_fn(out[0], y0, scaled_anchors[0])\n                + loss_fn(out[1], y1, scaled_anchors[1])\n                + loss_fn(out[2], y2, scaled_anchors[2])\n            )\n    return loss\nlr_finder = LRFinder(model, optimizer, criterion, device=device)\nlr_finder.range_test(train_loader, end_lr=10, num_iter=200, step_mode=\"exp\")\nlr_finder.plot() # to inspect the loss-learning rate graph\nlr_finder.reset() # to reset the model and optimizer to their initial state","metadata":{"id":"3P9vTBy475H1","colab":{"base_uri":"https://localhost:8080/","height":555,"referenced_widgets":["b860dacd46b742a999f5fadedb6b5884","1e2aeaa64b48448fb0c1c0879a895cc6","2259bcf6d7db4b219baa770fea64c831","9ac75756832f411e97447a0f99b57e65","677471cd448f4eb886d9efbb73beff0b","281339e008cf4cc8847168d8ee349539","a580d35996cd4ae0996b346ed270317f","d94579df92c9427f8375b2f5d13673cc","f940feab7ffe4abfbca64e58d1ba57e4","65d6c08800004855a545dac338cdc89e","52333d2b01104c418db95df1668a15fd"]},"outputId":"a2711398-2d5b-4cf4-fd64-7837f85c45f8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# NO NEED TO RUN THIS....FOR REFERENCE ONLY\n\nscaled_anchors = (\n    torch.tensor(config.ANCHORS)\n    * torch.tensor(config.S).unsqueeze(1).unsqueeze(1).repeat(1, 3, 2)\n).to(config.DEVICE)\n\n\nfrom torch.optim.lr_scheduler import OneCycleLR\nEPOCHS = config.NUM_EPOCHS * 2 // 5\nscheduler = OneCycleLR(\n        optimizer,\n        max_lr=1E-3,\n        steps_per_epoch=len(train_loader),\n        epochs=EPOCHS,\n        pct_start=5/EPOCHS,\n        div_factor=100,\n        three_phase=False,\n        final_div_factor=100,\n        anneal_strategy='linear'\n    )\n\nfor epoch in range(EPOCHS):\n    #plot_couple_examples(model, test_loader, 0.6, 0.5, scaled_anchors)\n    train_fn(train_loader, model, optimizer, loss_fn, scaler, scaled_anchors, scheduler)\n\n    #if config.SAVE_MODEL:\n    #   save_checkpoint(model, optimizer, filename=f\"checkpoint.pth.tar\")\n\n    print(f\"Currently epoch {epoch}\")\n    print(\"On Train Eval loader:\")\n    print(\"On Train loader:\")\n    check_class_accuracy(model, train_loader, threshold=config.CONF_THRESHOLD)\n\n    if epoch > 0 and epoch % 3 == 0:\n        check_class_accuracy(model, test_loader, threshold=config.CONF_THRESHOLD)\n        pred_boxes, true_boxes = get_evaluation_bboxes(\n            test_loader,\n            model,\n            iou_threshold=config.NMS_IOU_THRESH,\n            anchors=config.ANCHORS,\n            threshold=config.CONF_THRESHOLD,\n        )\n        mapval = mean_average_precision(\n            pred_boxes,\n            true_boxes,\n            iou_threshold=config.MAP_IOU_THRESH,\n            box_format=\"midpoint\",\n            num_classes=config.NUM_CLASSES,\n        )\n        print(f\"MAP: {mapval.item()}\")\n        model.train()","metadata":{"id":"_PQZ3wqP75H4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Pytorch Lightning Definitions**","metadata":{"id":"JG-vYgIZNS7J"}},{"cell_type":"markdown","source":"Define Model","metadata":{"id":"eZwoyfhNoH3A"}},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom pytorch_lightning import LightningModule\nfrom torchmetrics.functional import accuracy\n\n\nclass LitYOLOv3(LightningModule):\n    def __init__(self,\n                 loss_criterion,\n                 scaled_anchors,\n                 optimizer=None,\n                 scheduler_dict=None,\n                 num_classes=10,\n                 epochs=20):\n        super().__init__()\n\n        self.save_hyperparameters()\n        self.model = YOLOv3(num_classes=num_classes)\n        self.loss_criterion = loss_criterion\n        self.scaled_anchors = scaled_anchors\n        self.optimizer = None\n        self.scheduler_dict = None\n        self.epochs = epochs\n\n    def set_optimizer(self, optimizer):\n        self.optimizer = optimizer\n\n    def set_scheduler_dict(self, scheduler_dict):\n        self.scheduler_dict = scheduler_dict\n\n    def forward(self, x):\n        return self.model.forward(x)\n\n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        y0, y1, y2 = (y[0],y[1],y[2])\n\n        out = self(x)\n        loss = (\n                self.loss_criterion(out[0], y0, self.scaled_anchors[0]) +\n                self.loss_criterion(out[1], y1, self.scaled_anchors[1]) +\n                self.loss_criterion(out[2], y2, self.scaled_anchors[2])\n            )\n        self.log(\"train_loss\", loss, prog_bar=True)\n        return loss\n\n    def evaluate(self, batch, stage=None):\n        \"\"\"\n        Evaluate the model on validation dataset.\n        we compute the class accuracy, the no object accuracy, and the object accuracy\n        \"\"\"\n\n        tot_class_preds, correct_class = 0, 0\n        tot_noobj, correct_noobj = 0, 0\n        tot_obj, correct_obj = 0, 0\n        x, y = batch\n        out = self(x)\n\n        for i in range(3):\n            obj = y[i][..., 0] == 1 # in paper this is Iobj_i\n            noobj = y[i][..., 0] == 0  # in paper this is Iobj_i\n            correct_class += torch.sum(\n                torch.argmax(out[i][..., 5:][obj], dim=-1) == y[i][..., 5][obj]\n            )\n            tot_class_preds += torch.sum(obj)\n\n            obj_preds = torch.sigmoid(out[i][..., 0]) > threshold\n            correct_obj += torch.sum(obj_preds[obj] == y[i][..., 0][obj])\n            tot_obj += torch.sum(obj)\n            correct_noobj += torch.sum(obj_preds[noobj] == y[i][..., 0][noobj])\n            tot_noobj += torch.sum(noobj)\n\n        if stage:\n            class_acc = (correct_class/(tot_class_preds+1e-16))*100\n            no_obj_acc = (correct_noobj/(tot_noobj+1e-16))*100\n            obj_acc = (correct_obj/(tot_obj+1e-16))*100\n            self.log(f\"Class accuracy is: {class_acc:2f}%\", prog_bar=True)\n            self.log(f\"No obj accuracy is: {no_obj_acc:2f}%\", prog_bar=True)\n            self.log(f\"Obj accuracy is: {obj_acc:2f}%\", prog_bar=True)\n\n\n    def validation_step(self, batch, batch_idx):\n        self.evaluate(batch, \"val\")\n\n    def test_step(self, batch, batch_id):\n        self.evaluate(batch, \"test\")\n\n    def configure_optimizers(self):\n        return {\"optimizer\": self.optimizer, \"lr_scheduler\": self.scheduler_dict}\n\n\n","metadata":{"id":"OEH_n7lFNU5k","execution":{"iopub.status.busy":"2023-08-10T13:07:46.016784Z","iopub.execute_input":"2023-08-10T13:07:46.017581Z","iopub.status.idle":"2023-08-10T13:07:51.148136Z","shell.execute_reply.started":"2023-08-10T13:07:46.017541Z","shell.execute_reply":"2023-08-10T13:07:51.146908Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"Define DataModule","metadata":{"id":"fCmFIu5XoEU7"}},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom typing import List, Any\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom pytorch_lightning import LightningDataModule, seed_everything\nfrom dl_hub.models.YOLO_V3.dataset_org import YOLODataset\n\n\n\nclass YOLODataModule(LightningDataModule):\n    def __init__(self,\n                 csv_files,\n                 img_dir,\n                 label_dir,\n                 anchors,\n                 image_size=416,\n                 S=[13, 26, 52],\n                 C=20,\n                 train_transforms = None,\n                 val_transforms = None,\n                 test_transforms = None,\n                 val_split=0.2,\n                 num_workers = 1,\n                 pin_memory = False):\n\n        # Initialize the class. Set up the datadir, image dims, and num classes\n        super().__init__()\n        self.train_csv_path, self.test_csv_path = csv_files\n        self.img_dir = img_dir\n        self.label_dir = label_dir\n        self.anchors = anchors\n        self.image_size = image_size\n        self.train_transforms = train_transforms\n        self.val_transforms = val_transforms\n        self.test_transforms = test_transforms\n        self.val_split = val_split\n        self.S = S\n        self.C = C\n        self.num_workers = num_workers\n        self.pin_memory = pin_memory\n\n    def get_dataset_train(self):\n        return YOLODataset(self.train_csv_path,\n                           self.img_dir,\n                           self.label_dir,\n                           self.anchors,\n                           image_size=self.image_size,\n                           S=self.S,\n                           C=self.C,\n                           transform=self.train_transforms)\n\n\n    def get_dataset_test(self):\n        return YOLODataset(self.test_csv_path, \n                           self.img_dir,\n                           self.label_dir,\n                           self.anchors,\n                           image_size=self.image_size,\n                           S=self.S,\n                           C=self.C,\n                           transform=self.test_transforms)\n\n    def get_dataset_val(self):\n        return YOLODataset(self.train_csv_path,\n                           self.img_dir,\n                           self.label_dir,\n                           self.anchors,\n                           image_size=self.image_size,\n                           S=self.S,\n                           C=self.C,\n                           transform=self.test_transforms)\n\n\n    def _split_dataset(self, dataset: Dataset, train: bool = True) -> Dataset:\n        \"\"\"Splits the dataset into train and validation set.\"\"\"\n        len_dataset = len(dataset)\n        splits = self._get_splits(len_dataset)\n        dataset_train, dataset_val = random_split(dataset, splits, generator=torch.Generator().manual_seed(42))\n        if train:\n            return dataset_train\n        return dataset_val\n\n    def _get_splits(self, len_dataset: int) -> List[int]:\n        \"\"\"Computes split lengths for train and validation set.\"\"\"\n        if isinstance(self.val_split, int):\n            train_len = len_dataset - self.val_split\n            splits = [train_len, self.val_split]\n        elif isinstance(self.val_split, float):\n            val_len = int(self.val_split * len_dataset)\n            train_len = len_dataset - val_len\n            splits = [train_len, val_len]\n        else:\n            raise ValueError(f\"Unsupported type {type(self.val_split)}\")\n\n        return splits\n\n  \n    def prepare_data(self):\n        # Download the dataset\n        #YOLODataset(self.train_csv_path, \n        #            self.img_dir, \n        #            self.label_dir, \n        #            self.anchors,\n        #            image_size=self.image_size, \n        #            S=self.S,\n        #            C=self.C, \n        #            transform=self.train_transforms)\n        #YOLODataset(self.test_csv_path, \n        #            self.img_dir, \n        #            self.label_dir, \n        #            self.anchors,\n        #            image_size=self.image_size, \n        #            S=self.S,\n        #            C=self.C, \n        #            transform=self.test_transforms)\n        return\n\n    def setup(self, stage=None):\n        # Assign train/val datasets\n        if stage == 'fit' or stage is None:\n            dataset_train = self.get_dataset_train()\n            dataset_val = self.get_dataset_val()\n\n            # Split\n            self.train_dataset = self._split_dataset(dataset_train)\n            self.val_dataset = self._split_dataset(dataset_val, train=False)\n\n        if stage == 'test' or stage:\n            self.test_dataset = self.get_dataset_test()\n\n    def train_dataloader(self):\n        train_data_loader = DataLoader(\n            dataset=self.train_dataset,\n            batch_size=self.batch_size,\n            num_workers=self.num_workers,\n            pin_memory=self.pin_memory,\n            shuffle=True,\n            drop_last=False)\n        return train_data_loader\n\n    def val_dataloader(self):\n        val_data_loader = DataLoader(\n            dataset=self.train_eval_dataset,\n            batch_size=self.batch_size,\n            num_workers=self.num_workers,\n            pin_memory=self.pin_memory,\n            shuffle=False,\n            drop_last=False)\n        return val_data_loader\n\n    def test_dataloader(self):\n        test_data_loader = DataLoader(\n            dataset=self.test_dataset,\n            batch_size=self.batch_size,\n            num_workers=self.num_workers,\n            pin_memory=self.pin_memory,\n            shuffle=False,\n            drop_last=False)\n        return test_data_loader","metadata":{"id":"lxXXyGjxZlrx","execution":{"iopub.status.busy":"2023-08-10T13:08:56.637746Z","iopub.execute_input":"2023-08-10T13:08:56.638112Z","iopub.status.idle":"2023-08-10T13:08:56.657520Z","shell.execute_reply.started":"2023-08-10T13:08:56.638083Z","shell.execute_reply":"2023-08-10T13:08:56.656134Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"Put it all together!","metadata":{"id":"DE4icN1VpaBp"}},{"cell_type":"markdown","source":"Define Data Module","metadata":{"id":"Jo9tGpfAt81G"}},{"cell_type":"code","source":"# Define data module\ncsv_files = [config.DATASET + \"/100examples.csv\", config.DATASET + \"/8examples.csv\"]\ntrain_transforms=config.train_transforms\ntest_transforms=config.test_transforms\nval_transforms = test_transforms\nIMAGE_SIZE = config.IMAGE_SIZE\nS=[IMAGE_SIZE // 32, IMAGE_SIZE // 16, IMAGE_SIZE // 8]\nimg_dir=config.IMG_DIR\nlabel_dir=config.LABEL_DIR\nanchors=config.ANCHORS\nyolo_dm = YOLODataModule(\n                 csv_files,\n                 img_dir,\n                 label_dir,\n                 anchors,\n                 image_size=IMAGE_SIZE,\n                 S=S,\n                 C=20,\n                 train_transforms = train_transforms,\n                 val_transforms = val_transforms,\n                 test_transforms = test_transforms,\n                 val_split=0.1,\n                 num_workers = config.NUM_WORKERS,\n                 pin_memory = False)\nyolo_dm.prepare_data()\nyolo_dm.setup()","metadata":{"id":"RN7BkD6YoObb","execution":{"iopub.status.busy":"2023-08-10T13:09:05.388755Z","iopub.execute_input":"2023-08-10T13:09:05.389160Z","iopub.status.idle":"2023-08-10T13:09:05.416272Z","shell.execute_reply.started":"2023-08-10T13:09:05.389129Z","shell.execute_reply":"2023-08-10T13:09:05.415336Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def define_pl_model_resnet(params):\n    \"\"\"\n    Define a Pytorch Lightning for Resnet model\n    \"\"\"\n    base_lr = params['optimizer_params']['lr']\n    base_channels = params['base_channels']\n    num_classes = params['num_classes']\n    drop_out_probability = params['drop_out_probability']\n    num_epochs = params['num_epochs']\n    loss_func = params['loss_func']\n    resnet_model = LitResnet(loss_func, lr=base_lr,base_channels=base_channels, num_classes=num_classes,\n                    drop_out_probability=drop_out_probability, epochs=num_epochs)\n    optimizer = _define_optimizer(params, resnet_model)\n    scheduler_dict = _define_scheduler_dict(params, optimizer)\n    resnet_model.set_optimizer(optimizer)\n    resnet_model.set_scheduler_dict(scheduler_dict)\n    return resnet_model\n\n# Define model\nloss_criterion = YoloLoss()\nscaled_anchors = (\n    torch.tensor(config.ANCHORS)\n    * torch.tensor(config.S).unsqueeze(1).unsqueeze(1).repeat(1, 3, 2)\n).to(config.DEVICE)\noptimizer = optim.Adam(\n    model.parameters(), lr=config.LEARNING_RATE, weight_decay=config.WEIGHT_DECAY\n)\nyolo_model = LitYOLOv3(loss_criterion, scaled_anchors, optimizer=None, scheduler_dict=None, num_classes=20, epochs=20)\noptimizer =\nscheduler_dict = _define_scheduler_dict(params, optimizer)\n# Print Model Summary\nmodel_summary(resnet_model, input_size = (3,32,32))\n# train and eval model\ntrainer = train_and_eval_pl_model(params, resnet_model, cifar10_dm)","metadata":{"id":"VB2YNtDauAeW","trusted":true},"execution_count":null,"outputs":[]}]}